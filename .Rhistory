blogdown::serve_site()
file.edit(".gitignore")
blogdown::check_gitignore()
blogdown::check_gitignore()
blogdown::check_content()
blogdown::config_netlify()
blogdown::check_netlify()
blogdown::check_hugo()
blogdown::check_config()
blogdown::check_config()
blogdown::check_config()
blogdown::check_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::check_site
blogdown::check_site
blogdown::check_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown:::preview_site()
blogdown::serve_site()
blogdown::stop_server()
blogdown::serve_site()
blogdown::stop_server()
blogdown::new_post(title = "LDA vs QDA",)
blogdown::new_post(title = "LDA vs QDA",ext = '.Rmd',subdir = "post")
blogdown::new_post(title = "LDA vs QDA", ext = '.Rmd', subdir = "post")
blogdown:::preview_site()
knitr::opts_chunk$set(echo = TRUE)
kable1 <- confusionMatrix(t2)$table
knitr::opts_chunk$set(echo = TRUE)
#Import relevant libraries
library(MASS)
library(ggplot2)
library(gridExtra)
library(caret)
#Use functions from Q1 to generate datasets
sim_bvn <- function(u_1, u_2, mu, sigma) {
# Extract mean, standard deviations and rho from the mu and sigma variables
# passed to the function.
mu_1 <- mu[1]
mu_2 <- mu[2]
sigma_1 <- sqrt(sigma[1,1])
sigma_2 <- sqrt(sigma[2,2])
rho <- sigma[1,2]/(sigma_1*sigma_2)
# Start with u_1 to generate normal distribution with mean mu_1 and s.d. sigma_1
variate_1 <- qnorm(u_1, mean = mu_1, sd = sigma_1)
# Now we have x_1 values we can use qnorm and the distributional
# result from Q1.1 to calculate x_2 values
variate_2 <- qnorm(u_2, mean = mu_2 + ((sigma_2/sigma_1)*rho*(variate_1 - mu_1)),
sd = (1 - (rho^2))*(sigma_2^2))
result <- cbind(variate_1, variate_2)
if(nrow(result)==1) {
return(as.vector(result))
}
else{
return(result)
}
}
sim_bvn_mixture <- function(n, p, mu_list, sigma_list){
#calculate the number of variates that need to be generated for each component
n_per_component <- n * p
#create empty object to store results of for loop
result <- NULL
#iterate over length of vector p and use sim_bvn() to generate variates
for(i in 1:length(p)){
u_1 <- runif(n_per_component[i])
u_2 <- runif(n_per_component[i])
component_result <- sim_bvn(u_1, u_2, mu_list[[i]], sigma_list[[i]])
component_result <- cbind(component_result,i)
result <- rbind(result, component_result)
}
#change result type to data frame and rename columns
result <- as.data.frame(result)
colnames(result) <- c("y_1","y_2","component")
return(result)
}
set.seed(2345)
#mixed dataset with unequal covariance matrix
n <- 2000
p <- c(0.1,0.3,0.6)
mu_1 <- c(0,0)
mu_2 <- c(0,0)
mu_3 <- c(-2,-4)
mu_list <- list(mu_1,mu_2,mu_3)
sigma_1 <- matrix(c(1,0.7,0.7,1), byrow =TRUE, nrow =2)
sigma_2 <- matrix(c(1,-0.95,-0.95,1), byrow =TRUE, nrow =2)
sigma_3 <- matrix(c(0.25,0,0,4), byrow =TRUE, nrow =2)
sigma_list <- list(sigma_1, sigma_2, sigma_3)
unequal_cov <- sim_bvn_mixture(n, p, mu_list, sigma_list)
#generate mixed dataset with equal covariance matrix for each class
n <- 2000
p <- c(0.1,0.3,0.6)
mu_1 <- c(8,8)
mu_2 <- c(0,0)
mu_3 <- c(-8,-8)
mu_list <- list(mu_1,mu_2,mu_3)
sigma_1 <- matrix(c(5,0,0,4), byrow =TRUE, nrow =2)
sigma_2 <- matrix(c(5,0,0,4), byrow =TRUE, nrow =2)
sigma_3 <- matrix(c(5,0,0,4), byrow =TRUE, nrow =2)
sigma_list <- list(sigma_1, sigma_2, sigma_3)
equal_cov <- sim_bvn_mixture(n, p, mu_list, sigma_list)
#Plot both datasets
par(mfrow=c(1,2))
plot(equal_cov$y_1,equal_cov$y_2, col = equal_cov$component, xlab = "Y1", ylab = "Y2", main = "Equal Covariance")
plot(unequal_cov$y_1,unequal_cov$y_2, col = unequal_cov$component, xlab = "Y1", ylab = "Y2", main = "Unequal Covariance")
#create training index for each data set
train_idx_1 <- sample(n, round(0.025*n))
train_idx_2 <- sample(n, round(0.75*n))
equal_cov_train <- equal_cov[train_idx_1,]
equal_cov_test <- equal_cov[-train_idx_1, -3]
unequal_cov_train <- unequal_cov[train_idx_2,]
unequal_cov_test <- unequal_cov[-train_idx_2, -3]
#Fit LDA model to both datasets and evaluate performance
LDA_equal_train <- lda(component~., data = equal_cov_train)
LDA_equal_train_predict <- predict(LDA_equal_train)
t1 <- table(LDA_equal_train_predict$class, equal_cov_train$component, dnn = c("Predicted", "Truth"))
LDA_equal_test_predict <- predict(LDA_equal_train, equal_cov_test)
t2 <- table(LDA_equal_test_predict$class, equal_cov[-train_idx_1,]$component, dnn = c("Predicted", "Truth"))
#Fit LDA to unequal dataset
LDA_unequal_train <- lda(component~., data = unequal_cov_train)
LDA_unequal_train_predict <- predict(LDA_unequal_train)
t3 <- table(LDA_unequal_train_predict$class, unequal_cov_train$component, dnn = c("Predicted", "Truth"))
LDA_unequal_test_predict <- predict(LDA_unequal_train, unequal_cov_test)
t4 <- table(LDA_unequal_test_predict$class, unequal_cov[-train_idx_2,]$component, dnn = c("Predicted", "Truth"))
#Fit QDA to equal dataset
QDA_equal_train <- qda(component~., data = equal_cov_train)
QDA_equal_train_predict <- predict(QDA_equal_train)
t5 <- table(QDA_equal_train_predict$class, equal_cov_train$component, dnn = c("Predicted", "Truth"))
QDA_equal_test_predict <- predict(QDA_equal_train, equal_cov_test)
t6<- table(QDA_equal_test_predict$class, equal_cov[-train_idx_1,]$component, dnn = c("Predicted", "Truth"))
#Fit QDA to unequal dataset
QDA_unequal_train <- qda(component~., data = unequal_cov_train)
QDA_unequal_train_predict <- predict(QDA_unequal_train)
t7 <- table(QDA_unequal_train_predict$class, unequal_cov_train$component, dnn = c("Predicted", "Truth"))
QDA_unequal_test_predict <- predict(QDA_unequal_train, unequal_cov_test)
t8 <- table(QDA_unequal_test_predict$class, unequal_cov[-train_idx_2,]$component, dnn = c("Predicted", "Truth"))
kable1 <- confusionMatrix(t2)$table
knitr::kable(kable1)
blogdown:::preview_site()
